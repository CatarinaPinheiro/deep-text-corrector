{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import nltk\n",
    "\n",
    "from correct_text import train, decode, decode_sentence, evaluate_accuracy, create_model,\\\n",
    "    get_corrective_tokens, DefaultPTBConfig, DefaultMovieDialogConfig\n",
    "from text_corrector_data_readers import PTBDataReader, MovieDialogReader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_path = \"datasets/cornell movie-dialogs corpus\"\n",
    "train_path = os.path.join(root_data_path, \"movie_lines.txt0000\")\n",
    "val_path = os.path.join(root_data_path, \"movie_lines.txt0001\")\n",
    "test_path = os.path.join(root_data_path, \"movie_lines.txt0002\")\n",
    "model_path = os.path.join(root_data_path, \"dialog_correcter_model_testnltk\")\n",
    "config = DefaultMovieDialogConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reader = MovieDialogReader(config, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data; train = datasets/cornell movie-dialogs corpus/movie_lines.txt0000, test = datasets/cornell movie-dialogs corpus/movie_lines.txt0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0914 19:23:38.341596 140050958817088 deprecation_wrapper.py:119] From /media/catarina/DATA/git/deep-text-corrector/correct_text.py:143: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0914 19:23:38.378669 140050958817088 deprecation_wrapper.py:119] From /media/catarina/DATA/git/deep-text-corrector/text_corrector_models.py:74: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0914 19:23:38.432886 140050958817088 deprecation_wrapper.py:119] From /media/catarina/DATA/git/deep-text-corrector/text_corrector_models.py:108: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0914 19:23:38.433595 140050958817088 deprecation.py:506] From /home/catarina/anaconda3/envs/deep-learning/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0914 19:23:38.448377 140050958817088 deprecation.py:323] From /media/catarina/DATA/git/deep-text-corrector/text_corrector_models.py:121: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0914 19:23:38.449409 140050958817088 deprecation.py:323] From /media/catarina/DATA/git/deep-text-corrector/text_corrector_models.py:123: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0914 19:23:38.450430 140050958817088 deprecation.py:323] From /media/catarina/DATA/git/deep-text-corrector/text_corrector_models.py:126: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "W0914 19:23:38.451296 140050958817088 rnn_cell_impl.py:1642] At least two cells provided to MultiRNNCell are the same object and will share weights.\n",
      "W0914 19:23:38.452622 140050958817088 deprecation.py:323] From /media/catarina/DATA/git/deep-text-corrector/seq2seq.py:823: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 4 layers of 512 units.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0914 19:23:38.799648 140050958817088 deprecation.py:506] From /home/catarina/anaconda3/envs/deep-learning/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0914 19:23:39.406693 140050958817088 deprecation.py:506] From /home/catarina/anaconda3/envs/deep-learning/lib/python3.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell.py:183: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)])]\n",
      "[TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)])]\n",
      "[TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)])]\n",
      "[TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)]), TensorShape([Dimension(None), Dimension(1), Dimension(512)])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0914 19:23:52.851113 140050958817088 deprecation_wrapper.py:119] From /media/catarina/DATA/git/deep-text-corrector/text_corrector_models.py:194: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W0914 19:23:52.851612 140050958817088 deprecation_wrapper.py:119] From /media/catarina/DATA/git/deep-text-corrector/text_corrector_models.py:199: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "W0914 19:23:56.612573 140050958817088 deprecation.py:323] From /home/catarina/anaconda3/envs/deep-learning/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0914 19:24:25.659644 140050958817088 deprecation_wrapper.py:119] From /media/catarina/DATA/git/deep-text-corrector/text_corrector_models.py:211: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0914 19:24:25.660161 140050958817088 deprecation.py:323] From /media/catarina/DATA/git/deep-text-corrector/text_corrector_models.py:211: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "W0914 19:24:25.678213 140050958817088 deprecation.py:323] From /home/catarina/anaconda3/envs/deep-learning/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model with fresh parameters.\n",
      "Training bucket sizes: [48, 80306, 55100, 56500]\n",
      "Total train size: 191954.0\n"
     ]
    }
   ],
   "source": [
    "train(data_reader, train_path, val_path, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reader = MovieDialogReader(config, train_path, dropout_prob=0.25, replacement_prob=0.25, dataset_copies=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrective_tokens = get_corrective_tokens(data_reader, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(root_data_path, \"corrective_tokens.pickle\"), \"w\") as f:\n",
    "    pickle.dump(corrective_tokens, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(root_data_path, \"token_to_id.pickle\"), \"w\") as f:\n",
    "    pickle.dump(data_reader.token_to_id, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "model = create_model(sess, True, model_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test a sample from the test dataset.\n",
    "decoded = decode_sentence(sess, model, data_reader, \"you must have girlfriend\", corrective_tokens=corrective_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = decode_sentence(sess, model, data_reader,\n",
    "                          \"did n't you say that they 're going to develop this revolutionary new thing ...\",\n",
    "                          corrective_tokens=corrective_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_sentence(sess, model, data_reader, \"kvothe went to market\", corrective_tokens=corrective_tokens, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_sentence(sess, model, data_reader, \"blablahblah and bladdddd went to market\", corrective_tokens=corrective_tokens,\n",
    "                verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_sentence(sess, model, data_reader, \"do you have book\", corrective_tokens=corrective_tokens, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_sentence(sess, model, data_reader, \"the cardinals did better then the cubs\", corrective_tokens=corrective_tokens, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layers, 40k steps\n",
    "errors = evaluate_accuracy(sess, model, data_reader, corrective_tokens, test_path)#, max_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layers, 30k steps\n",
    "errors = evaluate_accuracy(sess, model, data_reader, corrective_tokens, test_path)#, max_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layers, 20k steps\n",
    "errors = evaluate_accuracy(sess, model, data_reader, corrective_tokens, test_path)#, max_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = evaluate_accuracy(sess, model, data_reader, corrective_tokens, test_path)#, max_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for decoding, target in errors:\n",
    "    print(\"Decoding: \" + \" \".join(decoding))\n",
    "    print(\"Target:   \" + \" \".join(target) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
